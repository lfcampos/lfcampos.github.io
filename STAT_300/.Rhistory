## put your code here
library(readr)
library(dplyr)
library(tidyr)
filename <- "~/Downloads/movielens-train.csv.gz"
ratings <- read_csv(gzfile(filename))
ratings %>% summarize(
n_users=n_distinct(userId),
n_movies=n_distinct(movieId),
min_rating=min(rating),
max_rating=max(rating))
library(knitr)
opts_chunk$set(cache = TRUE, message = FALSE)
## put your code here
library(readr)
library(dplyr)
library(tidyr)
filename <- "~/Downloads/movielens-train.csv.gz"
ratings <- read_csv(gzfile(filename))
ratings %>% summarize(
n_users=n_distinct(userId),
n_movies=n_distinct(movieId),
min_rating=min(rating),
max_rating=max(rating))
## put your code here
library(readr)
library(dplyr)
library(tidyr)
filename <- "~/Downloads/movielens-train.csv.gz"
ratings <- read_csv(gzfile(filename))
ratings %>% summarize(
n_users=n_distinct(userId),
n_movies=n_distinct(movieId),
min_rating=min(rating),
max_rating=max(rating))
## put your code here
library(readr)
library(dplyr)
library(tidyr)
filename <- "~/Downloads/movielens-train.csv.gz"
ratings <- read_csv(gzfile(filename))
ratings %>% summarize(
n_users=n_distinct(userId),
n_movies=n_distinct(movieId),
min_rating=min(rating),
max_rating=max(rating))
## put your code here
ratings %>% group_by(userId) %>%
summarize(n_movies=n()) %>%
summarize(median = median(n_movies), max = max(n_movies))
## put your code here
library(readr)
library(dplyr)
library(tidyr)
filename <- "~/Downloads/movielens-train.csv.gz"
ratings <- read_csv(gzfile(filename))
ratings %>% summarize(
n_users=n_distinct(userId),
n_movies=n_distinct(movieId),
min_rating=min(rating),
max_rating=max(rating))
filename
ratings <- read_csv(gzfile(filename))
ratings %>% summarize(
n_users=n_distinct(userId),
n_movies=n_distinct(movieId),
min_rating=min(rating),
max_rating=max(rating))
ratings %>% group_by(userId) %>%
summarize(n_movies=n()) %>%
summarize(median = median(n_movies), max = max(n_movies))
set.seed(755)
n_test <- round(nrow(ratings) / 10)
test_indices <- sample(1:nrow(ratings), n_test, replace=FALSE)
test <- ratings[test_indices,]
train <- ratings[-test_indices,]
rm(ratings) #to save space
RMSE <- function(true_ratings, predicted_ratings){
sqrt(mean((true_ratings - predicted_ratings)^2))
}
RMSE(true_ratings=c(4,3,3,4), predicted_ratings=c(4.5,3.5,1,4))
average_rating <- mean(train$rating)
predictions <- rep(average_rating, nrow(test))
naive_rmse <- RMSE(test$rating, predictions)
print(naive_rmse)
# compute an estimate for each b_i
mu <- mean(train$rating)
movie_means <- train %>%
group_by(movieId) %>%
summarize(b_i = mean(rating - mu))
### Explore the distribution
hist(movie_means$b_i)
### To make prediction use join
joined <- test %>%
left_join(movie_means, by='movieId') %>%
replace_na(list(b_i=0))
predicted_ratings <- mu + joined$b_i
print(RMSE(predicted_ratings, test$rating))
mu <- mean(train$rating)
movie_means <- train %>% ## as above but adding n_i
group_by(movieId) %>%
summarize(b_i = mean(rating - mu), n_i = n())
##now use join to add movie titles:
movies <- read_csv("https://raw.githubusercontent.com/datasciencelabs/data/master/movies.csv")
movie_means <- movie_means %>% left_join(movies)
## use arrange() to look at top 10 and bottom 10
arrange(movie_means, b_i) %>%
select(title, n_i, b_i) %>%
print(n=10)
arrange(movie_means, desc(b_i)) %>%
select(title, n_i, b_i) %>%
print(n=10)
lambda <- 5
mu <- mean(train$rating)
movie_reg_means <- train %>%
group_by(movieId) %>%
summarize(b_i = sum(rating - mu)/(n()+lambda), n_i = n())
movies <- read_csv("https://raw.githubusercontent.com/datasciencelabs/data/master/movies.csv")
movie_reg_means <- movie_reg_means %>% left_join(movies)
arrange(movie_reg_means, b_i) %>% select(title, n_i, b_i)
arrange(movie_reg_means, desc(b_i)) %>% select(title, n_i, b_i)
joined <- test %>%
left_join(movie_reg_means, by='movieId') %>%
replace_na(list(b_i=0))
predicted_ratings <- mu + joined$b_i
print(RMSE(predicted_ratings, test$rating))
##To see what happens
library(ggplot2)
data_frame(original = movie_means$b_i,
regularlized = movie_reg_means$b_i,
n = movie_reg_means$n) %>%
ggplot(aes(original, regularlized, size=log10(n))) +
geom_point(shape=1, alpha=0.5)
user_means <- train %>%
group_by(userId) %>%
summarize(b_u=mean(rating)) %>%
ggplot(aes(b_u)) + geom_histogram()
##we compute movie_means again to have
##all code in same place
lambda <- 5
alpha <- 10
mu <- mean(train$rating)
movie_reg_means <- train %>% ##as above but adding n_i
group_by(movieId) %>%
summarize(b_i = sum(rating - mu)/(n()+lambda))
user_reg_means <- train %>% left_join(movie_reg_means) %>%
mutate(resids = rating - mu - b_i) %>% group_by(userId) %>%
summarize(b_u = sum(resids)/(n()+alpha))
joined <- test %>%
left_join(movie_reg_means, by='movieId') %>%
left_join(user_reg_means, by='userId') %>%
replace_na(list(b_i=0, b_u=0))
predicted_ratings <- mu + joined$b_i + joined$b_u
print(RMSE(predicted_ratings, test$rating)) #0.8683076
?confusionMatrix
??confusionMatrix
library(knitr)
opts_chunk$set(cache = TRUE, message = FALSE)
## put your code here
library(readr)
library(dplyr)
library(tidyr)
filename <- "~/Downloads/movielens-train.csv.gz"
ratings <- read_csv(gzfile(filename))
ratings %>% summarize(
n_users=n_distinct(userId),
n_movies=n_distinct(movieId),
min_rating=min(rating),
max_rating=max(rating))
## put your code here
ratings %>% group_by(userId) %>%
summarize(n_movies=n()) %>%
summarize(median = median(n_movies), max = max(n_movies))
## put your code here
set.seed(755)
n_test <- round(nrow(ratings) / 10)
test_indices <- sample(1:nrow(ratings), n_test, replace=FALSE)
test <- ratings[test_indices,]
train <- ratings[-test_indices,]
rm(ratings) #to save space
## put your code here
RMSE <- function(true_ratings, predicted_ratings){
sqrt(mean((true_ratings - predicted_ratings)^2))
}
RMSE(true_ratings=c(4,3,3,4), predicted_ratings=c(4.5,3.5,1,4))
## put your code here
average_rating <- mean(train$rating)
predictions <- rep(average_rating, nrow(test))
naive_rmse <- RMSE(test$rating, predictions)
print(naive_rmse)
## put your code here
# compute an estimate for each b_i
mu <- mean(train$rating)
movie_means <- train %>%
group_by(movieId) %>%
summarize(b_i = mean(rating - mu))
### Explore the distribution
hist(movie_means$b_i)
### To make prediction use join
joined <- test %>%
left_join(movie_means, by='movieId') %>%
replace_na(list(b_i=0))
predicted_ratings <- mu + joined$b_i
print(RMSE(predicted_ratings, test$rating))
## put your code here
mu <- mean(train$rating)
movie_means <- train %>% ## as above but adding n_i
group_by(movieId) %>%
summarize(b_i = mean(rating - mu), n_i = n())
##now use join to add movie titles:
movies <- read_csv("https://raw.githubusercontent.com/datasciencelabs/data/master/movies.csv")
movie_means <- movie_means %>% left_join(movies)
## use arrange() to look at top 10 and bottom 10
arrange(movie_means, b_i) %>%
select(title, n_i, b_i) %>%
print(n=10)
arrange(movie_means, desc(b_i)) %>%
select(title, n_i, b_i) %>%
print(n=10)
## put your code here
lambda <- 5
mu <- mean(train$rating)
movie_reg_means <- train %>%
group_by(movieId) %>%
summarize(b_i = sum(rating - mu)/(n()+lambda), n_i = n())
movies <- read_csv("https://raw.githubusercontent.com/datasciencelabs/data/master/movies.csv")
movie_reg_means <- movie_reg_means %>% left_join(movies)
arrange(movie_reg_means, b_i) %>% select(title, n_i, b_i)
arrange(movie_reg_means, desc(b_i)) %>% select(title, n_i, b_i)
joined <- test %>%
left_join(movie_reg_means, by='movieId') %>%
replace_na(list(b_i=0))
predicted_ratings <- mu + joined$b_i
print(RMSE(predicted_ratings, test$rating))
##To see what happens
library(ggplot2)
data_frame(original = movie_means$b_i,
regularlized = movie_reg_means$b_i,
n = movie_reg_means$n) %>%
ggplot(aes(original, regularlized, size=log10(n))) +
geom_point(shape=1, alpha=0.5)
## put your code here
user_means <- train %>%
group_by(userId) %>%
summarize(b_u=mean(rating)) %>%
ggplot(aes(b_u)) + geom_histogram()
## put your code here
##we compute movie_means again to have
##all code in same place
lambda <- 5
alpha <- 10
mu <- mean(train$rating)
movie_reg_means <- train %>% ##as above but adding n_i
group_by(movieId) %>%
summarize(b_i = sum(rating - mu)/(n()+lambda))
user_reg_means <- train %>% left_join(movie_reg_means) %>%
mutate(resids = rating - mu - b_i) %>% group_by(userId) %>%
summarize(b_u = sum(resids)/(n()+alpha))
joined <- test %>%
left_join(movie_reg_means, by='movieId') %>%
left_join(user_reg_means, by='userId') %>%
replace_na(list(b_i=0, b_u=0))
predicted_ratings <- mu + joined$b_i + joined$b_u
print(RMSE(predicted_ratings, test$rating)) #0.8683076
train_small <- train %>%
filter(movieId %in% unique(test$movieId) & userId %in% unique(test$userId)) %>%
group_by(movieId) %>%
filter(n()>=5000) %>%
ungroup %>%
group_by(userId) %>%
filter(n()>=250) %>%
ungroup
## put your code here
## movie_reg_means and user_reg_means come from 2E
train_small <- train_small %>%
left_join(movie_reg_means, by='movieId') %>%
left_join(user_reg_means, by='userId') %>%
mutate(resids = rating - mu - b_i - b_u)
train_small
Y <- train_small %>%
select(userId, movieId, resids) %>%
spread(userId, resids)
Y
dim(Y)
train_small
length(unique(train_small$userId))
Y <- train_small %>%
select(userId, movieId, resids) %>%
spread(userId, resids) %>%
left_join(movies)
dim(Y)
Y <- train_small %>%
select(userId, movieId, resids) %>%
spread(userId, resids) %>%
left_join(movies) %>%
select(-genres) %>%
mutate(title = gsub("\\s\\([^)]*\\)","",title)) ##remove the year
movie_ids <- Y$movieId
movie_titles <- Y$title
Y <- select(Y, -movieId, -title) %>% as.matrix
Y[is.na(Y)] <- 0
